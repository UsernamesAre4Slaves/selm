# Active Learning Configuration for SELM
active_learning:
  enabled: true           # Set to true to enable active learning during training
  
  strategy: "uncertainty_sampling"  # Strategy to use for selecting samples (options: uncertainty_sampling, random_sampling, diversity_sampling, entropy_based)
  
  # Parameters for uncertainty sampling strategy
  uncertainty_sampling:
    method: "least_confident"  # Uncertainty method (options: least_confident, margin, entropy)
    uncertainty_threshold: 0.2 # Confidence threshold for uncertainty sampling (lower means more uncertain samples will be selected)
    batch_size: 100            # Number of samples to query at each iteration

  # Parameters for diversity sampling strategy
  diversity_sampling:
    diversity_method: "core_set"  # Method for diversity sampling (options: core_set, cluster_based)
    similarity_metric: "cosine"   # Metric to use for similarity calculation (options: cosine, euclidean)
    batch_size: 50                # Number of samples to query for diversity

  # General parameters for active learning
  query_frequency: 5         # Frequency (in epochs) to query new samples for labeling
  max_iterations: 20         # Maximum number of active learning iterations
  initial_labeled_ratio: 0.1 # Percentage of the dataset to label initially
  query_batch_size: 200      # Number of new data points to label in each query round

  # Stopping criteria for active learning
  early_stopping:
    enabled: true             # Enable early stopping based on model performance
    patience: 3               # Number of query rounds to wait before stopping if no improvement
    min_delta: 0.001          # Minimum performance improvement to consider
  
  # Logging and tracking options
  logging:
    log_active_learning: true  # Log active learning process
    save_intermediate_models: true  # Save models after each query round
    log_path: "logs/active_learning.log" # Path for saving the logs
  
  # Evaluation parameters
  evaluation:
    metrics: ["accuracy", "f1_score", "roc_auc"]  # Metrics to track during active learning
    eval_frequency: 2           # Frequency (in query rounds) to run evaluations
    test_set_ratio: 0.2         # Ratio of the dataset to reserve for final evaluation
