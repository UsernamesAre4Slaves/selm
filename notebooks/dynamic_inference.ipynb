{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Inference in SELM\n",
    "\n",
    "This notebook explores dynamic inference techniques, including early exit strategies and conditional computation, to improve inference efficiency in the SELM model. Dynamic inference allows the model to skip unnecessary computation for faster and more resource-efficient predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.model.transformer import SELMTransformer\n",
    "from src.optimization.dynamic_inference import EarlyExitStrategy, ConditionalComputation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pre-trained SELM Model\n",
    "\n",
    "Load a pre-trained SELM model to run dynamic inference experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model (assumes a pre-trained model exists at 'model_checkpoint.pth')\n",
    "model = SELMTransformer.load_from_checkpoint('model_checkpoint.pth')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Test Dataset\n",
    "\n",
    "We'll use a sample dataset for testing dynamic inference techniques. This can be customized or replaced with a larger evaluation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a sample dataset (example text inputs)\n",
    "test_data = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"Artificial intelligence is transforming industries.\",\n",
    "    \"The SELM model is highly efficient for various NLP tasks.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Early Exit Strategy\n",
    "\n",
    "The early exit strategy enables the model to dynamically decide whether it can terminate computation earlier in the transformer layers based on confidence scores. This method helps reduce the overall computational cost of inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the early exit strategy\n",
    "early_exit = EarlyExitStrategy(threshold=0.9)  # Exit if confidence exceeds 0.9\n",
    "\n",
    "# Run the model with early exit\n",
    "for text in test_data:\n",
    "    inputs = model.tokenize(text)\n",
    "    output, layers_used = early_exit(model, inputs)\n",
    "    print(f\"Input: {text}\")\n",
    "    print(f\"Output: {output}, Layers Used: {layers_used}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Layer Utilization with Early Exit\n",
    "\n",
    "Let's visualize how many layers are used during inference with the early exit strategy applied to different inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track layers used per input\n",
    "layers_used = []\n",
    "for text in test_data:\n",
    "    inputs = model.tokenize(text)\n",
    "    _, used = early_exit(model, inputs)\n",
    "    layers_used.append(used)\n",
    "\n",
    "# Visualization\n",
    "plt.barh([f'Input {i+1}' for i in range(len(test_data))], layers_used)\n",
    "plt.xlabel('Layers Used')\n",
    "plt.title('Early Exit Layer Utilization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Conditional Computation\n",
    "\n",
    "Conditional computation selectively activates parts of the model based on the complexity of the input, which can improve both speed and efficiency during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the conditional computation strategy\n",
    "conditional_computation = ConditionalComputation()\n",
    "\n",
    "# Run the model with conditional computation\n",
    "for text in test_data:\n",
    "    inputs = model.tokenize(text)\n",
    "    output = conditional_computation(model, inputs)\n",
    "    print(f\"Input: {text}\")\n",
    "    print(f\"Output: {output}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking Inference Time\n",
    "\n",
    "Let's measure the inference time with and without dynamic inference techniques to quantify the performance improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure inference time without dynamic inference\n",
    "start_time = time()\n",
    "for text in test_data:\n",
    "    inputs = model.tokenize(text)\n",
    "    model(inputs)\n",
    "baseline_time = time() - start_time\n",
    "print(f\"Baseline Inference Time: {baseline_time:.4f} seconds\")\n",
    "\n",
    "# Measure inference time with early exit\n",
    "start_time = time()\n",
    "for text in test_data:\n",
    "    inputs = model.tokenize(text)\n",
    "    early_exit(model, inputs)\n",
    "early_exit_time = time() - start_time\n",
    "print(f\"Early Exit Inference Time: {early_exit_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In this notebook, we demonstrated how dynamic inference techniques like early exit and conditional computation can significantly improve the efficiency of the SELM model during inference. These methods reduce computational cost by skipping unnecessary layers or computations based on the input."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
