{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SELM Hyperparameter Search\n",
    "\n",
    "In this notebook, we will perform hyperparameter tuning for the SELM model using Optuna. We'll configure and run an Optuna study to find the best hyperparameters for our model.\n",
    "\n",
    "## 1. Setup\n",
    "Import necessary libraries and load configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "import yaml\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "# Load configuration\n",
    "def load_config(config_path):\n",
    "    with open(config_path, 'r') as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "config = load_config('../config/optuna_config.yaml')\n",
    "\n",
    "# Load tokenizer\n",
    "model_name = 'distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset('glue', 'mrpc')\n",
    "\n",
    "# Tokenize dataset\n",
    "def tokenize_fn(examples):\n",
    "    return tokenizer(examples['sentence'], padding='max_length', truncation=True, max_length=128)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_fn, batched=True)\n",
    "train_dataset = tokenized_dataset['train']\n",
    "test_dataset = tokenized_dataset['test']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define the Objective Function\n",
    "Define the objective function for Optuna to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Hyperparameters\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [8, 16, 32])\n",
    "    num_epochs = trial.suggest_int('num_epochs', 3, 10)\n",
    "\n",
    "    # Model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "    # TrainingArguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        num_train_epochs=num_epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "        evaluation_strategy='steps',\n",
    "        save_steps=500,\n",
    "        load_best_model_at_end=True\n",
    "    )\n",
    "\n",
    "    # Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    # Train and evaluate\n",
    "    trainer.train()\n",
    "    eval_results = trainer.evaluate()\n",
    "    return eval_results['eval_accuracy']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run the Optuna Study\n",
    "Configure and run the Optuna study to find the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study: study_name=seml_hyperparameter_tuning\n",
      "Number of trials: 10\n"
     ]
    }
   ],
   "source": [
    "# Create Optuna study\n",
    "study = optuna.create_study(\n",
    "    study_name=config['study_name'],\n",
    "    direction=config['direction']\n",
    ") \n",
    "\n",
    "# Optimize\n",
    "study.optimize(objective, n_trials=config['n_trials'], timeout=config['timeout'])\n",
    "\n",
    "# Print best parameters\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "print(f'  Value: {trial.value}')\n",
    "print(f'  Params:')\n", 
    "for key, value in trial.params.items():\n",
    "    print(f'    {key}: {value}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save the Results\n",
    "Save the results of the Optuna study for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save study results\n",
    "joblib.dump(study, 'optuna_results/study.pkl')\n",
    "print('Optuna study saved to optuna_results/study.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
